{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence-to-sequence models are best suited for tasks revolving around generating new sentences depending on a given input, such as summarization, translation, or generative question answering.\n",
    "\n",
    "## Representatives of this family of models include:\n",
    "\n",
    "-BART\n",
    "\n",
    "-mBART\n",
    "\n",
    "-Marian\n",
    "\n",
    "-T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (4.34.0)\n",
      "Requirement already satisfied: torch in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: sentencepiece in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (0.1.99)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.17 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: filelock in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: networkx in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: jinja2 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: fsspec in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: sympy in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.2.140)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from requests->transformers) (2.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# install the necessary libraries\n",
    "\n",
    "!pip install transformers torch sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peshal/drishya/nlpBasics/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)tencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:00<00:00, 10.2MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 9.10M/9.10M [00:01<00:00, 8.87MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.35k/1.35k [00:00<00:00, 4.09MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 1.22G/1.22G [01:58<00:00, 10.3MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2SeqLMOutput(loss=tensor(0.2023, grad_fn=<NllLossBackward0>), logits=tensor([[[ 8.9348, 10.0298, 13.8504,  ...,  8.4704,  8.9632,  9.6498],\n",
       "         [ 1.4863,  2.9584,  2.7080,  ...,  1.7190,  0.8060,  3.2427],\n",
       "         [ 1.5690,  3.3232,  4.7880,  ...,  3.1595,  3.1562,  3.1856],\n",
       "         ...,\n",
       "         [ 2.9676,  3.2773,  6.6141,  ...,  3.2888,  2.9244,  2.6752],\n",
       "         [ 1.1856,  3.0159, 16.9462,  ...,  2.5549,  3.1475,  3.3301],\n",
       "         [ 3.8511,  3.0228,  6.6920,  ...,  3.7765,  3.5099,  2.7210]]],\n",
       "       grad_fn=<AddBackward0>), past_key_values=None, decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[-6.9505e-01,  8.3922e-01, -7.9732e-01,  ..., -8.0697e-01,\n",
       "           7.1792e-01, -7.6232e-02],\n",
       "         [ 5.9379e-01,  1.9463e+00, -1.1604e+00,  ...,  6.2286e-01,\n",
       "           2.7843e-01,  1.1886e-01],\n",
       "         [ 7.8062e-01, -5.2735e-01,  1.9515e-01,  ..., -3.0932e-01,\n",
       "           9.4584e-01,  4.0067e-01],\n",
       "         ...,\n",
       "         [-4.6730e-01,  5.7295e-01, -1.9679e-01,  ...,  1.6841e-01,\n",
       "          -5.3776e-01, -5.9740e-01],\n",
       "         [-2.8431e-03, -7.4553e-03,  8.6579e-03,  ..., -1.8092e-02,\n",
       "           3.2751e-03, -1.0392e-02],\n",
       "         [ 2.5268e-02,  5.3714e-03, -6.3904e-03,  ..., -1.5345e-02,\n",
       "          -1.6598e-03, -1.4490e-02]]], grad_fn=<NativeLayerNormBackward0>), encoder_hidden_states=None, encoder_attentions=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBartTokenizer\n",
    "\n",
    "tokenizer = MBartTokenizer.from_pretrained(\"facebook/mbart-large-en-ro\", src_lang=\"en_XX\", tgt_lang=\"ro_RO\")\n",
    "example_english_phrase = \"UN Chief Says There Is No Military Solution in Syria\"\n",
    "expected_translation_romanian = \"Şeful ONU declară că nu există o soluţie militară în Siria\"\n",
    "\n",
    "inputs = tokenizer(example_english_phrase, text_target=expected_translation_romanian, return_tensors=\"pt\")\n",
    "\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-en-ro\")\n",
    "# forward pass\n",
    "model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aşadar, haideţi să vedem dacă funcţionează cu adevărat, încercând modelul mBART de la HuggingFace.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generation\n",
    "\n",
    "tokenizer = MBartTokenizer.from_pretrained(\"facebook/mbart-large-en-ro\", src_lang=\"en_XX\")\n",
    "article = \"So, let's see if it actually works. This is me trying sequence-to-sequence model mBART from HuggingFace.\"\n",
    "inputs = tokenizer(article, return_tensors=\"pt\")\n",
    "translated_tokens = model.generate(**inputs, decoder_start_token_id=tokenizer.lang_code_to_id[\"ro_RO\"])\n",
    "tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text in Romanian:\n",
      "Odată, într-un pământ departe, departe.\n"
     ]
    }
   ],
   "source": [
    "english_prompt = \"Once upon a time, in a land far, far away\"\n",
    "\n",
    "# Tokenize the prompt\n",
    "input_ids = tokenizer.encode(english_prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate text in Romanian\n",
    "output = model.generate(input_ids, max_length=100, num_beams=4, length_penalty=2.0, early_stopping=True, decoder_start_token_id=model.config.pad_token_id)\n",
    "\n",
    "# Decode the generated text\n",
    "generated_text_romanian = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the generated text in Romanian\n",
    "print(\"Generated Text in Romanian:\")\n",
    "print(generated_text_romanian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary in Romanian:\n",
      "Hugging Face creează un instrument care democratizează AI. Inteligența artificială (AI) are potențialul de a revoluționa diferite industrii. Hugging Face oferă o gamă largă de modele și biblioteci LNL.\n"
     ]
    }
   ],
   "source": [
    "# Define the input text you want to summarize in English\n",
    "input_text = \"\"\"\n",
    "Hugging Face is creating a tool that democratizes AI. Artificial Intelligence (AI) has the potential to revolutionize various industries. \n",
    "Hugging Face provides a wide range of NLP models and libraries.\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "# Generate a summary in Romanian\n",
    "summary_ids = model.generate(input_ids, max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
    "\n",
    "# Decode and print the generated summary in Romanian\n",
    "generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(\"Generated Summary in Romanian:\")\n",
    "print(generated_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
